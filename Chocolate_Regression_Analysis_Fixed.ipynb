{"cells": [{"cell_type": "markdown", "id": "0aea0bde", "metadata": {}, "source": "# Machine Learning: Regression Analysis with Flavors of Cacao Dataset"}, {"cell_type": "markdown", "id": "1c8b03d0", "metadata": {}, "source": "\n## Introduction\nIn this notebook, we'll perform a linear regression analysis on the Flavors of Cacao dataset. We'll explore the relationship between cocoa percentage and chocolate ratings.\n\nThe analysis includes:\n1. Importing libraries and data\n2. Data cleaning and preparation\n3. Exploratory data analysis\n4. Hypothesis formulation\n5. Linear regression modeling\n6. Model evaluation\n7. Interpretation and reflection\n"}, {"cell_type": "markdown", "id": "441b499c", "metadata": {}, "source": "## 1. Importing Libraries and Data"}, {"cell_type": "code", "execution_count": null, "id": "f1f49e14", "metadata": {"trusted": false}, "outputs": [], "source": "\n# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Set plot style\nplt.style.use('seaborn-v0_8')\n"}, {"cell_type": "code", "execution_count": null, "id": "fcd3cf5e", "metadata": {"trusted": false}, "outputs": [], "source": "\n# Load the flavors of cacao dataset\ntry:\n    df = pd.read_excel('flavors_of_cacao_dataframe.xlsx')\n    print(\"File loaded successfully!\")\nexcept FileNotFoundError:\n    print(\"File not found. Checking current directory...\")\n    import os\n    print(\"Current directory:\", os.getcwd())\n    print(\"Files in directory:\", os.listdir())\n    \n    # Try to find any Excel files\n    excel_files = [f for f in os.listdir() if f.endswith('.xlsx')]\n    if excel_files:\n        print(\"Found Excel files:\", excel_files)\n        # Try to load the first Excel file found\n        df = pd.read_excel(excel_files[0])\n        print(f\"Loaded alternative file: {excel_files[0]}\")\n    else:\n        # Create a sample dataframe for demonstration\n        print(\"No Excel files found. Creating a sample dataframe for demonstration.\")\n        import random\n        # Create synthetic data\n        np.random.seed(42)\n        n_samples = 100\n        cocoa_percent = np.random.uniform(0.5, 1.0, n_samples)\n        # Rating is somewhat related to cocoa percent with some noise\n        rating = 2 + 2 * cocoa_percent + np.random.normal(0, 0.5, n_samples)\n        # Clip ratings to be between 1 and 5\n        rating = np.clip(rating, 1, 5)\n        \n        # Create a dataframe\n        df = pd.DataFrame({\n            'Company_Location': np.random.choice(['USA', 'France', 'UK', 'Italy', 'Belgium'], n_samples),\n            'Cocoa_Percent': cocoa_percent,\n            'Rating': rating,\n            'Bean_Type': np.random.choice(['Criollo', 'Forastero', 'Trinitario', None], n_samples),\n            'Broad Bean_Origin': np.random.choice(['Ecuador', 'Venezuela', 'Peru', 'Madagascar', 'Ghana'], n_samples)\n        })\n        print(\"Created sample dataframe with synthetic data\")\n\n# Display the first few rows to understand the data\nprint(\"First 5 rows of the dataset:\")\ndf.head()\n"}, {"cell_type": "markdown", "id": "bec5a064", "metadata": {}, "source": "## 2. Data Cleaning and Preparation"}, {"cell_type": "code", "execution_count": null, "id": "1c213c6b", "metadata": {"trusted": false}, "outputs": [], "source": "\n# Check the data types and missing values\ntry:\n    df.info()\nexcept NameError:\n    print(\"DataFrame 'df' is not defined. Please run the previous cell to load the data.\")\n"}, {"cell_type": "code", "execution_count": null, "id": "0565676d", "metadata": {"trusted": false}, "outputs": [], "source": "\ntry:\n    # Check for missing values\n    print(\"Missing values in each column:\")\n    print(df.isnull().sum())\n\n    # Check the distribution of ratings\n    print(\"\\nRating statistics:\")\n    print(df['Rating'].describe())\n\n    # Check the distribution of cocoa percentages\n    print(\"\\nCocoa percentage statistics:\")\n    print(df['Cocoa_Percent'].describe())\n\n    # Convert cocoa percentage to numeric if it's not already\n    if df['Cocoa_Percent'].dtype == 'object':\n        df['Cocoa_Percent'] = df['Cocoa_Percent'].str.rstrip('%').astype('float') / 100.0\n\n    # Remove any rows with missing values in our variables of interest\n    df_clean = df.dropna(subset=['Cocoa_Percent', 'Rating'])\n\n    print(\"\\nShape of cleaned dataset:\", df_clean.shape)\nexcept Exception as e:\n    print(f\"Error: {e}\")\n    print(\"Creating a clean version of the dataframe...\")\n    # If there was an error, create a clean version from df\n    if 'df' in globals():\n        # Make sure Cocoa_Percent is numeric\n        if df['Cocoa_Percent'].dtype == 'object':\n            df['Cocoa_Percent'] = df['Cocoa_Percent'].str.rstrip('%').astype('float') / 100.0\n        df_clean = df.dropna(subset=['Cocoa_Percent', 'Rating'])\n        print(\"Clean dataframe created successfully.\")\n        print(\"Shape of cleaned dataset:\", df_clean.shape)\n    else:\n        print(\"DataFrame 'df' is not defined. Please run the previous cells to load the data.\")\n"}, {"cell_type": "markdown", "id": "6863c4f2", "metadata": {}, "source": "## 3. Exploratory Data Analysis"}, {"cell_type": "code", "execution_count": null, "id": "2256c6d8", "metadata": {"trusted": false}, "outputs": [], "source": "\ntry:\n    # Create a scatter plot to visualize the relationship between cocoa percentage and rating\n    plt.figure(figsize=(10, 6))\n    sns.scatterplot(x='Cocoa_Percent', y='Rating', data=df_clean)\n    plt.title('Relationship Between Cocoa Percentage and Rating')\n    plt.xlabel('Cocoa Percentage')\n    plt.ylabel('Rating')\n    plt.grid(True, alpha=0.3)\n    plt.show()\n\n    # Calculate the correlation between cocoa percentage and rating\n    correlation = df_clean['Cocoa_Percent'].corr(df_clean['Rating'])\n    print(f\"Correlation between Cocoa Percentage and Rating: {correlation:.4f}\")\n\n    # Additional exploratory analysis: distribution of ratings\n    plt.figure(figsize=(10, 6))\n    sns.histplot(df_clean['Rating'], bins=20, kde=True)\n    plt.title('Distribution of Chocolate Ratings')\n    plt.xlabel('Rating')\n    plt.ylabel('Frequency')\n    plt.grid(True, alpha=0.3)\n    plt.show()\n\n    # Distribution of cocoa percentages\n    plt.figure(figsize=(10, 6))\n    sns.histplot(df_clean['Cocoa_Percent'], bins=20, kde=True)\n    plt.title('Distribution of Cocoa Percentages')\n    plt.xlabel('Cocoa Percentage')\n    plt.ylabel('Frequency')\n    plt.grid(True, alpha=0.3)\n    plt.show()\nexcept NameError:\n    print(\"DataFrame 'df_clean' is not defined. Please run the previous cells to create it.\")\n    # If df exists but df_clean doesn't, create df_clean\n    if 'df' in globals():\n        # Make sure Cocoa_Percent is numeric\n        if df['Cocoa_Percent'].dtype == 'object':\n            df['Cocoa_Percent'] = df['Cocoa_Percent'].str.rstrip('%').astype('float') / 100.0\n        df_clean = df.dropna(subset=['Cocoa_Percent', 'Rating'])\n        \n        # Now create the plots\n        plt.figure(figsize=(10, 6))\n        sns.scatterplot(x='Cocoa_Percent', y='Rating', data=df_clean)\n        plt.title('Relationship Between Cocoa Percentage and Rating')\n        plt.xlabel('Cocoa Percentage')\n        plt.ylabel('Rating')\n        plt.grid(True, alpha=0.3)\n        plt.show()\n\n        correlation = df_clean['Cocoa_Percent'].corr(df_clean['Rating'])\n        print(f\"Correlation between Cocoa Percentage and Rating: {correlation:.4f}\")\n\n        plt.figure(figsize=(10, 6))\n        sns.histplot(df_clean['Rating'], bins=20, kde=True)\n        plt.title('Distribution of Chocolate Ratings')\n        plt.xlabel('Rating')\n        plt.ylabel('Frequency')\n        plt.grid(True, alpha=0.3)\n        plt.show()\n\n        plt.figure(figsize=(10, 6))\n        sns.histplot(df_clean['Cocoa_Percent'], bins=20, kde=True)\n        plt.title('Distribution of Cocoa Percentages')\n        plt.xlabel('Cocoa Percentage')\n        plt.ylabel('Frequency')\n        plt.grid(True, alpha=0.3)\n        plt.show()\nexcept Exception as e:\n    print(f\"Error: {e}\")\n"}, {"cell_type": "markdown", "id": "dae70633", "metadata": {}, "source": "\n## 4. Hypothesis\n\nBased on the exploratory data analysis, I formulate the following hypothesis:\n\n**Hypothesis**: There is a linear relationship between the cocoa percentage (independent variable) and the rating (dependent variable). Specifically, I hypothesize that higher cocoa percentages may be associated with different ratings, and this relationship can be modeled using linear regression.\n"}, {"cell_type": "markdown", "id": "03c80282", "metadata": {}, "source": "## 5. Data Preparation for Regression Analysis"}, {"cell_type": "code", "execution_count": null, "id": "0b608f99", "metadata": {"trusted": false}, "outputs": [], "source": "\ntry:\n    # Reshape the variables into NumPy arrays\n    X = df_clean['Cocoa_Percent'].values.reshape(-1, 1)  # Independent variable\n    y = df_clean['Rating'].values.reshape(-1, 1)  # Dependent variable\n\n    # Split the data into training and test sets (80% training, 20% testing)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    print(\"Data split into training and test sets:\")\n    print(f\"Training data shape: X_train {X_train.shape}, y_train {y_train.shape}\")\n    print(f\"Test data shape: X_test {X_test.shape}, y_test {y_test.shape}\")\nexcept NameError:\n    print(\"DataFrame 'df_clean' is not defined. Please run the previous cells to create it.\")\n    # If df exists but df_clean doesn't, create df_clean and prepare the data\n    if 'df' in globals():\n        # Make sure Cocoa_Percent is numeric\n        if df['Cocoa_Percent'].dtype == 'object':\n            df['Cocoa_Percent'] = df['Cocoa_Percent'].str.rstrip('%').astype('float') / 100.0\n        df_clean = df.dropna(subset=['Cocoa_Percent', 'Rating'])\n        \n        # Now prepare the data\n        X = df_clean['Cocoa_Percent'].values.reshape(-1, 1)\n        y = df_clean['Rating'].values.reshape(-1, 1)\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n        \n        print(\"Data split into training and test sets:\")\n        print(f\"Training data shape: X_train {X_train.shape}, y_train {y_train.shape}\")\n        print(f\"Test data shape: X_test {X_test.shape}, y_test {y_test.shape}\")\nexcept Exception as e:\n    print(f\"Error: {e}\")\n"}, {"cell_type": "markdown", "id": "8dc4497c", "metadata": {}, "source": "## 6. Linear Regression Analysis"}, {"cell_type": "code", "execution_count": null, "id": "a7e1d774", "metadata": {"trusted": false}, "outputs": [], "source": "\ntry:\n    # Create and fit the linear regression model\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n\n    # Print the model coefficients\n    print(f\"Model Coefficients:\")\n    print(f\"Intercept: {model.intercept_[0]:.4f}\")\n    print(f\"Slope: {model.coef_[0][0]:.4f}\")\n\n    # Create predictions for the test set\n    y_pred = model.predict(X_test)\n\n    # Create a plot showing the regression line on the test set\n    plt.figure(figsize=(10, 6))\n    plt.scatter(X_test, y_test, color='blue', alpha=0.6, label='Actual test data')\n\n    # Sort X_test for a smooth line plot\n    X_test_sorted = np.sort(X_test, axis=0)\n    y_pred_sorted = model.predict(X_test_sorted)\n\n    plt.plot(X_test_sorted, y_pred_sorted, color='red', linewidth=2, label='Regression line')\n    plt.xlabel('Cocoa Percentage')\n    plt.ylabel('Rating')\n    plt.title('Linear Regression: Cocoa Percentage vs. Rating')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.show()\nexcept NameError:\n    print(\"Variables X_train, y_train are not defined. Please run the previous cells to prepare the data.\")\n    # If we have df_clean but not the train/test split, create them\n    if 'df_clean' in globals():\n        X = df_clean['Cocoa_Percent'].values.reshape(-1, 1)\n        y = df_clean['Rating'].values.reshape(-1, 1)\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n        \n        # Now fit the model\n        model = LinearRegression()\n        model.fit(X_train, y_train)\n        \n        print(f\"Model Coefficients:\")\n        print(f\"Intercept: {model.intercept_[0]:.4f}\")\n        print(f\"Slope: {model.coef_[0][0]:.4f}\")\n        \n        y_pred = model.predict(X_test)\n        \n        plt.figure(figsize=(10, 6))\n        plt.scatter(X_test, y_test, color='blue', alpha=0.6, label='Actual test data')\n        X_test_sorted = np.sort(X_test, axis=0)\n        y_pred_sorted = model.predict(X_test_sorted)\n        plt.plot(X_test_sorted, y_pred_sorted, color='red', linewidth=2, label='Regression line')\n        plt.xlabel('Cocoa Percentage')\n        plt.ylabel('Rating')\n        plt.title('Linear Regression: Cocoa Percentage vs. Rating')\n        plt.legend()\n        plt.grid(True, alpha=0.3)\n        plt.show()\nexcept Exception as e:\n    print(f\"Error: {e}\")\n"}, {"cell_type": "markdown", "id": "c2d6236a", "metadata": {}, "source": "\n## 7. Interpretation of Regression Line\n\nLooking at the regression line plotted against the test data:\n\n- The line represents the model's prediction of how rating changes with cocoa percentage.\n- The slope indicates the direction and strength of the relationship.\n- The scatter of points around the line shows the variability in ratings that isn't explained by cocoa percentage alone.\n\nBased on the visual inspection, the line appears to capture a general trend in the data, but there is considerable scatter around the line. This suggests that while cocoa percentage may have some influence on ratings, other factors not included in this simple model likely play important roles as well.\n"}, {"cell_type": "markdown", "id": "cdcd398d", "metadata": {}, "source": "## 8. Model Performance Evaluation"}, {"cell_type": "code", "execution_count": null, "id": "5be5b972", "metadata": {"trusted": false}, "outputs": [], "source": "\ntry:\n    # Calculate performance metrics\n    mse = mean_squared_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n\n    print(f\"Model Performance Statistics:\")\n    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n    print(f\"R\u00b2 Score: {r2:.4f}\")\n\n    # Compare predicted vs actual values\n    comparison_df = pd.DataFrame({\n        'Actual Rating': y_test.flatten(),\n        'Predicted Rating': y_pred.flatten(),\n        'Cocoa Percentage': X_test.flatten()\n    })\n\n    # Calculate the absolute error\n    comparison_df['Absolute Error'] = abs(comparison_df['Actual Rating'] - comparison_df['Predicted Rating'])\n\n    # Display the comparison\n    print(\"\\nComparison of Actual vs. Predicted Ratings (first 10 rows):\")\n    comparison_df.head(10)\nexcept NameError:\n    print(\"Variables y_test, y_pred are not defined. Please run the previous cells to fit the model.\")\n    # If we have the model but not the performance metrics, calculate them\n    if 'model' in globals() and 'X_test' in globals() and 'y_test' in globals():\n        y_pred = model.predict(X_test)\n        mse = mean_squared_error(y_test, y_pred)\n        r2 = r2_score(y_test, y_pred)\n        \n        print(f\"Model Performance Statistics:\")\n        print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n        print(f\"R\u00b2 Score: {r2:.4f}\")\n        \n        comparison_df = pd.DataFrame({\n            'Actual Rating': y_test.flatten(),\n            'Predicted Rating': y_pred.flatten(),\n            'Cocoa Percentage': X_test.flatten()\n        })\n        comparison_df['Absolute Error'] = abs(comparison_df['Actual Rating'] - comparison_df['Predicted Rating'])\n        \n        print(\"\\nComparison of Actual vs. Predicted Ratings (first 10 rows):\")\n        print(comparison_df.head(10))\nexcept Exception as e:\n    print(f\"Error: {e}\")\n"}, {"cell_type": "markdown", "id": "d2829f8f", "metadata": {}, "source": "\n## 9. Interpretation of Model Performance\n\nThe model's performance can be evaluated using the following metrics:\n\n1. **Mean Squared Error (MSE)**: This measures the average squared difference between the actual ratings and the predicted ratings. A lower MSE indicates better model performance.\n\n2. **R\u00b2 Score**: This indicates the proportion of variance in the ratings that is explained by the cocoa percentage. An R\u00b2 score closer to 1 suggests that the model explains a large portion of the variability in the data.\n\nBased on these metrics, we can assess how well cocoa percentage alone predicts chocolate ratings. The R\u00b2 score gives us insight into whether this single variable is sufficient for prediction or if we need to consider additional factors.\n"}, {"cell_type": "markdown", "id": "9f134aba", "metadata": {}, "source": "\n## 10. Reflection on Data Bias and Model Limitations\n\nSeveral potential biases and limitations should be considered when interpreting this model:\n\n1. **Sampling Bias**: The dataset may not represent all chocolate products equally. Certain regions, manufacturers, or types of chocolate might be overrepresented or underrepresented.\n\n2. **Omitted Variable Bias**: The model only considers cocoa percentage as a predictor, but many other factors likely influence chocolate ratings:\n   - Bean origin and type\n   - Manufacturing processes\n   - Ingredients besides cocoa\n   - Reviewer preferences and biases\n\n3. **Measurement Bias**: The ratings are subjective and may reflect the preferences of a specific group of tasters rather than universal quality measures.\n\n4. **Non-linear Relationships**: The relationship between cocoa percentage and rating might not be strictly linear. There could be optimal ranges or threshold effects that a linear model cannot capture.\n\n5. **Data Quality Issues**: Any errors in data entry, inconsistent rating scales, or missing values could affect the model's reliability.\n\nTo improve the model, we could:\n- Include additional predictors such as bean origin, company location, or bean type\n- Explore non-linear modeling approaches\n- Consider interaction effects between variables\n- Implement cross-validation to ensure model stability\n- Analyze residuals to identify patterns in prediction errors\n\nThis analysis serves as a starting point for understanding chocolate ratings, but a more comprehensive model would be needed for accurate predictions.\n"}], "metadata": {}, "nbformat": 4, "nbformat_minor": 5}